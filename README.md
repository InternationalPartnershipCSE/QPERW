# Workshop on Quantitative Physics Education Research, University of Colorado, Boulder and JILA. June 8-10, 2020

Welcome to the website for the workshop on Quantitative Physics Education Research. 

## Introduction

This workshop is organized by an international partnership between Michigan State University,
Oregon State University, the University of Colorado at Boulder and the University of Oslo. The University of Oslo with its 
center of excellence in Education _Center for Computing in Science Education_, is the leading institution.  
The partnership is sponsored by the Norwegian Research Council under the International Partnership program INTPART (add link). 

The present workshop aims at gathering people from the cross cutting fields of physics education research (PER), statistics, computational social science, and educational data mining to come together for three days to discuss the current and future state of quantitative PER. Organized under three overarching topics of of data sources, statistical methods, and visualization tools this workshop has the ambitious goal of:

- Identify new research directions in PER that can be answered via quantitative analysis
- Identify new developments in machine learning and statistics communities that can directly address open research questions in PER
- Identify currently existing data sources that can be exploited with new methods such as machine learning and text mining
- Identify missing data that can be collected via surveys, institutional data, etc. for research exploitation
- Identifying the core skills and practices of quantitative research in PER to motivate a 2021 summer school for grad students and postdocs

This workshop will give participants the opportunity to participate in working groups discussing the three overarching topics, see plenary talks from established scientists across social science, and participate as invited speakers presenting their own work. Participants will also have the chance to participate in community building activities and experience the city of Boulder, Colorado.

This workshop will be hosted at JILA, a joint institute between the University of Colorado, Boulder and NIST (add links). 


### Background
Computing competence represents a central element in scientific
problem solving, from basic education and research to essentially all
advanced problems in modern societies.  To integrate computing in our
education is thus of strategic importance for study programs at the
university level as it will give our students the competences and
skills needed to meet future job market requirements.  

These competences are not limited to STEM fields only. The statistical
analysis of big data sets and how to use machine learning algorithms
belong to the set of tools needed by almost all disciplines, spanning
from the Social Sciences, Law, Education to the traditional STEM
fields and Life Science.  Unfortunately, many of our students at both
the undergraduate and the graduate levels are unprepared to use
computational modeling, data science, and high performance computing,
skills that are much valued by a broad range of employers. This lack
of preparation is most certainly no fault of our students, but rather
a broader issue associated with how departments, colleges, and
universities are keeping up with the demands of these high-tech
employers. 

The integration of computing across all science disciplines is a key
element in the educational strategy of most universities worldwide. 
Thus, an  important aspect of this workshop is to discuss new assessments
and new assessment methods that address several issues associated with
integrating computation into science courses. The issues include but
are not limited to how well students learn computing, what new
insights students gain about the specific science through computing,
and how students' affective states (e.g., motivation to learn,
computational self-efficacy) are affected by computing. Broadly
speaking, these assessments should provide deeper insights into the
integration of computing in science education in general as well as
provide a structured framework for assessment of our efforts and a
basis for systematic studies of student learning.  The central
questions that would like to address are 
- How can we assess the effect of integrating computing into science curricula on a variety of learned-centered constructs including computational thinking, motivation, self-efficacy and science identity formation; 
- How should we structure assessments to ensure valid, reliable and impactful assessment;  
- how can the use of these structured assessments improve student outcomes in teacher-, peer-, and self-assessment.


Addressing these and many other questions requires a combination of qualitative
techniques to construct the focus of these assessments, to build
assessment items and to develop appropriate assessment methods, and
quantitative techniques, including advanced statistical analysis to
ensure validity and reliability of the proposed methods as well as to
analyze the resulting data.  


###  Program June 8-10, 2020
- _Monday, June 8: 
- _Tuesday, June 9: 
- _Wednesday Lecture, June 10:

### Participants
